{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9323232,"sourceType":"datasetVersion","datasetId":5647839}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Image Classification of Animals","metadata":{}},{"cell_type":"markdown","source":"**Introduction**      \nImage classification is a fundamental problem in computer vision, and animal classification is a particularly challenging task due to the vast variability in species, poses, and backgrounds. To tackle this problem, we'll employ a convolutional neural network (CNN) architecture, leveraging its ability to automatically and adaptively learn spatial hierarchies of features from images. By utilizing a pre-trained CNN as a feature extractor, we'll fine-tune the model on our dataset, exploiting the transfer learning paradigm to adapt the learned representations to our specific task.","metadata":{}},{"cell_type":"markdown","source":"**Dataset: A Compendium of Animal Images**  \nOur dataset comprises 15 classes, each corresponding to a distinct animal species, with images of size 224 x 224 x 3. This dataset presents a unique opportunity to explore the efficacy of various CNN architectures like VGG16, ResNet50, InceptionV3, MobileNetV2, EfficientNetB7 etc....","metadata":{}},{"cell_type":"markdown","source":"**Model Configuration**  \nAfter conducting a thorough review of the literature and drawing from personal experience, I have selected EfficientNetB7 as the base model for transfer learning due to its impressive performance on image classification tasks, and Adam as the optimization algorithm, as I believe its adaptive learning rate and momentum capabilities will effectively navigate the complexities of our dataset and optimize the model's parameters for superior performance.","metadata":{}},{"cell_type":"markdown","source":"**Technical Specifications**  \n-Image dimensions: 224 x 224 x 3  \n-Number of classes: 15  \n-CNN architecture: EfficientNetB7 (base model for transfer learning)  \n-Optimization algorithm: Adam  \n-Loss function: Categorical Cross-Entropy  \n-Evaluation metric: Top-1 Accuracy  ","metadata":{}},{"cell_type":"markdown","source":"**PYTHON CODE**","metadata":{}},{"cell_type":"markdown","source":"Importing necessary libraries\n","metadata":{}},{"cell_type":"code","source":"import random\nimport pandas as pd\nimport numpy as np\nimport itertools\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\n\nimport cv2\nimport seaborn as sns\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt\n\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Dropout, BatchNormalization\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow import keras\n\nfrom pathlib import Path\nimport os.path\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:20.610960Z","iopub.execute_input":"2024-09-07T10:19:20.611924Z","iopub.status.idle":"2024-09-07T10:19:34.616729Z","shell.execute_reply.started":"2024-09-07T10:19:20.611881Z","shell.execute_reply":"2024-09-07T10:19:34.615705Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"Additional Imports","metadata":{}},{"cell_type":"code","source":"!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n\nfrom helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, compare_historys, walk_through_dir, pred_and_plot\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:34.618379Z","iopub.execute_input":"2024-09-07T10:19:34.618932Z","iopub.status.idle":"2024-09-07T10:19:36.117272Z","shell.execute_reply.started":"2024-09-07T10:19:34.618895Z","shell.execute_reply":"2024-09-07T10:19:36.115586Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n","output_type":"stream"},{"name":"stdout","text":"--2024-09-07 10:19:35--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\nResolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\nConnecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 10246 (10K) [text/plain]\nSaving to: 'helper_functions.py'\n\nhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0.001s  \n\n2024-09-07 10:19:35 (9.08 MB/s) - 'helper_functions.py' saved [10246/10246]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport random\n\ndef seed_everything(seed=42):\n    # Seed value for TensorFlow\n    tf.random.set_seed(seed)\n\n    # Seed value for NumPy\n    np.random.seed(seed)\n\n    # Seed value for Python's random library\n    random.seed(seed)\n\n    # Force TensorFlow to use single thread\n    # Multiple threads are a potential source of non-reproducible results.\n    session_conf = tf.compat.v1.ConfigProto(\n        intra_op_parallelism_threads=1,\n        inter_op_parallelism_threads=1\n    )\n\n    # Make sure that TensorFlow uses a deterministic operation wherever possible\n    tf.compat.v1.set_random_seed(seed)\n\n    sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n\nseed_everything()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:36.121001Z","iopub.execute_input":"2024-09-07T10:19:36.121468Z","iopub.status.idle":"2024-09-07T10:19:36.440745Z","shell.execute_reply.started":"2024-09-07T10:19:36.121416Z","shell.execute_reply":"2024-09-07T10:19:36.439728Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"Dataset Loading and Configuration","metadata":{}},{"cell_type":"code","source":"# Specify the dataset directory\ndataset = \"/kaggle/input/animal/Animal Classification/dataset\"\n\n# Walk through the dataset directory to explore its contents\nwalk_through_dir(dataset)\n\n# Set the batch size for training\nbatchsize = 32\n\n# Set the target image size for resizing\ntargetsize = (224, 224)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:36.443208Z","iopub.execute_input":"2024-09-07T10:19:36.444066Z","iopub.status.idle":"2024-09-07T10:19:37.260060Z","shell.execute_reply.started":"2024-09-07T10:19:36.444031Z","shell.execute_reply":"2024-09-07T10:19:37.259129Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"There are 15 directories and 0 images in '/kaggle/input/animal/Animal Classification/dataset'.\nThere are 0 directories and 130 images in '/kaggle/input/animal/Animal Classification/dataset/Horse'.\nThere are 0 directories and 131 images in '/kaggle/input/animal/Animal Classification/dataset/Lion'.\nThere are 0 directories and 122 images in '/kaggle/input/animal/Animal Classification/dataset/Dog'.\nThere are 0 directories and 125 images in '/kaggle/input/animal/Animal Classification/dataset/Bear'.\nThere are 0 directories and 137 images in '/kaggle/input/animal/Animal Classification/dataset/Bird'.\nThere are 0 directories and 129 images in '/kaggle/input/animal/Animal Classification/dataset/Tiger'.\nThere are 0 directories and 126 images in '/kaggle/input/animal/Animal Classification/dataset/Kangaroo'.\nThere are 0 directories and 133 images in '/kaggle/input/animal/Animal Classification/dataset/Elephant'.\nThere are 0 directories and 137 images in '/kaggle/input/animal/Animal Classification/dataset/Zebra'.\nThere are 0 directories and 131 images in '/kaggle/input/animal/Animal Classification/dataset/Cow'.\nThere are 0 directories and 135 images in '/kaggle/input/animal/Animal Classification/dataset/Panda'.\nThere are 0 directories and 129 images in '/kaggle/input/animal/Animal Classification/dataset/Giraffe'.\nThere are 0 directories and 129 images in '/kaggle/input/animal/Animal Classification/dataset/Dolphin'.\nThere are 0 directories and 123 images in '/kaggle/input/animal/Animal Classification/dataset/Cat'.\nThere are 0 directories and 127 images in '/kaggle/input/animal/Animal Classification/dataset/Deer'.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Transforming Dataset Directory into a DataFrame","metadata":{}},{"cell_type":"code","source":"def directory_to_dataframe(data_path):\n    \"\"\"\n    Transforms the dataset directory into a structured table.\n\n    Args:\n        data_path (str): Path to the dataset directory.\n\n    Returns:\n        pd.DataFrame: DataFrame containing filepaths and labels.\n    \"\"\"\n    directory = Path(data_path)\n\n    # Gather filepaths and corresponding labels\n    file_locations = list(directory.glob(r'**/*.JPG')) + list(directory.glob(r'**/*.jpg')) + list(directory.glob(r'**/*.jpeg')) + list(directory.glob(r'**/*.PNG'))\n\n    category_labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1], file_locations))\n\n    file_series = pd.Series(file_locations, name='Filepath').astype(str)\n    label_series = pd.Series(category_labels, name='Label')\n\n    # Combine filepaths and labels into a single table\n    dataset_table = pd.concat([file_series, label_series], axis=1)\n    return dataset_table\n\n# Transform the dataset directory into a DataFrame\ndataset_df = directory_to_dataframe(dataset)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:37.261230Z","iopub.execute_input":"2024-09-07T10:19:37.261541Z","iopub.status.idle":"2024-09-07T10:19:37.432032Z","shell.execute_reply.started":"2024-09-07T10:19:37.261509Z","shell.execute_reply":"2024-09-07T10:19:37.431221Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"Handling Unidentified Image Files","metadata":{}},{"cell_type":"code","source":"import PIL\nfrom pathlib import Path\nfrom PIL import UnidentifiedImageError\n\n# Iterate over all JPEG files in the dataset directory\nimage_files = Path(dataset).rglob(\"*.jpg\")\n\n# Identify and report any files that cannot be opened as images\nfor file_path in image_files:\n    try:\n        img = PIL.Image.open(file_path)\n    except PIL.UnidentifiedImageError:\n        print(f\"Error: Unable to open image file - {file_path}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:37.433174Z","iopub.execute_input":"2024-09-07T10:19:37.433516Z","iopub.status.idle":"2024-09-07T10:19:45.338081Z","shell.execute_reply.started":"2024-09-07T10:19:37.433483Z","shell.execute_reply":"2024-09-07T10:19:45.337265Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"Splitting Data into Training and Testing Sets","metadata":{}},{"cell_type":"code","source":"# Divide the dataset into training and testing subsets\ntraining_data, testing_data = train_test_split(dataset_df, test_size=0.2, shuffle=True, random_state=42)\n\n# Define data generators for training and testing data\ntraining_data_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n    validation_split=0.2\n)\n\ntesting_data_generator = ImageDataGenerator(\n    preprocessing_function=tf.keras.applications.efficientnet.preprocess_input,\n)\n\n# Create data flows for training, validation, and testing data\ntraining_data_flow = training_data_generator.flow_from_dataframe(\n    dataframe=training_data,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=targetsize,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batchsize,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n\nvalidation_data_flow = training_data_generator.flow_from_dataframe(\n    dataframe=training_data,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=targetsize,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batchsize,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)\n\ntesting_data_flow = testing_data_generator.flow_from_dataframe(\n    dataframe=testing_data,\n    x_col='Filepath',\n    y_col='Label',\n    target_size=targetsize,\n    color_mode='rgb',\n    class_mode='categorical',\n    batch_size=batchsize,\n    shuffle=False\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:45.339230Z","iopub.execute_input":"2024-09-07T10:19:45.339560Z","iopub.status.idle":"2024-09-07T10:19:45.796457Z","shell.execute_reply.started":"2024-09-07T10:19:45.339526Z","shell.execute_reply":"2024-09-07T10:19:45.795462Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Found 1244 validated image filenames belonging to 15 classes.\nFound 311 validated image filenames belonging to 15 classes.\nFound 389 validated image filenames belonging to 15 classes.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Defining Image Augmentation Pipeline","metadata":{}},{"cell_type":"code","source":"# Define a sequential pipeline for image augmentation\nfrom tensorflow.keras.layers import *\nimage_augmentation_pipeline = tf.keras.Sequential([\n  Resizing(224, 224),  # Resize images to a fixed size\n  Rescaling(1./255),  # Normalize pixel values to the range [0, 1]\n  RandomFlip(\"horizontal\"),  # Randomly flip images horizontally\n  RandomRotation(0.1),  # Randomly rotate images by up to 10 degrees\n  RandomZoom(0.1),  # Randomly zoom in or out by up to 10%\n  RandomContrast(0.1),  # Randomly adjust image contrast by up to 10%\n])\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:45.797740Z","iopub.execute_input":"2024-09-07T10:19:45.798074Z","iopub.status.idle":"2024-09-07T10:19:46.155450Z","shell.execute_reply.started":"2024-09-07T10:19:45.798041Z","shell.execute_reply":"2024-09-07T10:19:46.154609Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":"Loading Pre-Trained EfficientNetB7 Model","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained EfficientNetB7 model\nbase_model = tf.keras.applications.efficientnet.EfficientNetB7(\n    input_shape=(224, 224, 3),  # Input shape of the model\n    include_top=False,  # Exclude the classification head\n    weights='imagenet',  # Use weights pre-trained on ImageNet\n    pooling='max'  # Use max pooling as the pooling layer\n)\n\n# Freeze the pre-trained model's weights\nbase_model.trainable = False\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:19:46.156628Z","iopub.execute_input":"2024-09-07T10:19:46.156922Z","iopub.status.idle":"2024-09-07T10:20:03.713114Z","shell.execute_reply.started":"2024-09-07T10:19:46.156891Z","shell.execute_reply":"2024-09-07T10:20:03.712195Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb7_notop.h5\n\u001b[1m258076736/258076736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 0us/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Defining Model Callbacks (Callbacks are functions that monitor and control the training process, allowing us to save the best model, stop training when progress stalls, and adjust the learning rate for better convergence.)","metadata":{}},{"cell_type":"code","source":"# Define the file path for model checkpointing\ncheckpoint_file_path = \"animals_classification_model_checkpoint.weights.h5\"\n\n# Create a ModelCheckpoint callback to save the model's weights at each epoch\ncheckpoint_callback = ModelCheckpoint(\n    checkpoint_file_path,\n    save_weights_only=True,  # Only save the model's weights\n    monitor=\"val_accuracy\",  # Monitor the validation accuracy metric\n    save_best_only=True  # Only save the best-performing model\n)\n\n# Define an EarlyStopping callback to stop training if the model's validation loss doesn't improve for 5 epochs\nearly_stopping_callback = EarlyStopping(\n    monitor=\"val_loss\",  # Watch the validation loss metric\n    patience=5,  # Wait for 5 epochs before stopping training\n    restore_best_weights=True  # Restore the best-performing model's weights\n)\n\n# Define a ReduceLROnPlateau callback to reduce the learning rate if the model's validation loss doesn't improve for 3 epochs\nlearning_rate_reduction_callback = ReduceLROnPlateau(\n    monitor=\"val_loss\",  # Watch the validation loss metric\n    factor=0.2,  # Reduce the learning rate by a factor of 0.2\n    patience=3,  # Wait for 3 epochs before reducing the learning rate\n    min_lr=1e-6  # Minimum learning rate\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:20:03.715999Z","iopub.execute_input":"2024-09-07T10:20:03.716362Z","iopub.status.idle":"2024-09-07T10:20:03.723246Z","shell.execute_reply.started":"2024-09-07T10:20:03.716325Z","shell.execute_reply":"2024-09-07T10:20:03.722219Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Defining the Model Architecture","metadata":{}},{"cell_type":"code","source":"# Get the input layer of the pre-trained model\nmodel_inputs = base_model.input\n\n# Apply data augmentation to the input layer\naugmented_inputs = image_augmentation_pipeline(model_inputs)\n\n# Define the custom model architecture\n# 1. Dense layer with 128 units, ReLU activation (output is 0 for negative inputs, f(x) = x for positive inputs, selected for its simplicity and ability to introduce non-linearity), batch normalization (normalizes inputs for each layer to have zero mean and unit variance, selected to normalize inputs and stabilize training), and dropout (selected to prevent overfitting)\nx = Dense(128, activation='relu')(base_model.output)\nx = BatchNormalization()(x)  # Normalizes the inputs for each layer to have zero mean and unit variance, selected to normalize inputs and stabilize training\nx = Dropout(0.45)(x)  # Selected to prevent overfitting\n\n# 2. Dense layer with 256 units, ReLU activation, and batch normalization\nx = Dense(256, activation='relu')(x)\nx = BatchNormalization()(x)  # Normalizes the inputs for each layer to have zero mean and unit variance, selected to normalize inputs and stabilize training\nx = Dropout(0.45)(x)  # Selected to prevent overfitting\n\n# 3. Output layer with 15 units, softmax activation (outputs a probability distribution over all classes, ensuring the probabilities add up to 1, selected to output a probability distribution over all classes)\nmodel_outputs = Dense(15, activation='softmax')(x)\n\n# Create the custom model\ncustom_model = Model(inputs=model_inputs, outputs=model_outputs)\n\n# Compile the custom model\ncustom_model.compile(\n    optimizer=Adam(0.00001),\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:43:57.348674Z","iopub.execute_input":"2024-09-07T10:43:57.349079Z","iopub.status.idle":"2024-09-07T10:43:57.531698Z","shell.execute_reply.started":"2024-09-07T10:43:57.349042Z","shell.execute_reply":"2024-09-07T10:43:57.530896Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"Training the Model","metadata":{}},{"cell_type":"code","source":"# Train the model on the training data\nhistory = custom_model.fit(\n    training_data_flow,\n    validation_data=validation_data_flow,\n    epochs=100,  # Number of epochs to train for\n    callbacks=[\n        #early_stopping_callback,  # Stop training if validation loss doesn't improve\n        checkpoint_callback,  # Save the best model\n        learning_rate_reduction_callback  # Reduce learning rate if validation loss doesn't improve\n    ]\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T10:51:50.433451Z","iopub.execute_input":"2024-09-07T10:51:50.434316Z","iopub.status.idle":"2024-09-07T11:05:50.441292Z","shell.execute_reply.started":"2024-09-07T10:51:50.434270Z","shell.execute_reply":"2024-09-07T11:05:50.440530Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 206ms/step - accuracy: 0.1304 - loss: 3.5242 - val_accuracy: 0.3055 - val_loss: 2.2428 - learning_rate: 1.0000e-05\nEpoch 2/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.1612 - loss: 3.1465 - val_accuracy: 0.3730 - val_loss: 2.1055 - learning_rate: 1.0000e-05\nEpoch 3/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.1697 - loss: 3.1490 - val_accuracy: 0.4148 - val_loss: 1.9854 - learning_rate: 1.0000e-05\nEpoch 4/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.1838 - loss: 2.9467 - val_accuracy: 0.4469 - val_loss: 1.8669 - learning_rate: 1.0000e-05\nEpoch 5/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.2158 - loss: 2.8124 - val_accuracy: 0.4855 - val_loss: 1.7553 - learning_rate: 1.0000e-05\nEpoch 6/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.2570 - loss: 2.6995 - val_accuracy: 0.5113 - val_loss: 1.6711 - learning_rate: 1.0000e-05\nEpoch 7/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.2736 - loss: 2.5488 - val_accuracy: 0.5241 - val_loss: 1.5773 - learning_rate: 1.0000e-05\nEpoch 8/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.2712 - loss: 2.4865 - val_accuracy: 0.5531 - val_loss: 1.5028 - learning_rate: 1.0000e-05\nEpoch 9/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.2927 - loss: 2.4755 - val_accuracy: 0.5949 - val_loss: 1.4479 - learning_rate: 1.0000e-05\nEpoch 10/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.3521 - loss: 2.3014 - val_accuracy: 0.6206 - val_loss: 1.3915 - learning_rate: 1.0000e-05\nEpoch 11/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.3473 - loss: 2.2590 - val_accuracy: 0.6367 - val_loss: 1.3380 - learning_rate: 1.0000e-05\nEpoch 12/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.3895 - loss: 2.1379 - val_accuracy: 0.6527 - val_loss: 1.3003 - learning_rate: 1.0000e-05\nEpoch 13/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.3959 - loss: 2.1168 - val_accuracy: 0.6656 - val_loss: 1.2667 - learning_rate: 1.0000e-05\nEpoch 14/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.3618 - loss: 2.1859 - val_accuracy: 0.6817 - val_loss: 1.2218 - learning_rate: 1.0000e-05\nEpoch 15/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.3930 - loss: 2.0656 - val_accuracy: 0.6849 - val_loss: 1.1824 - learning_rate: 1.0000e-05\nEpoch 16/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.4146 - loss: 1.9882 - val_accuracy: 0.7010 - val_loss: 1.1510 - learning_rate: 1.0000e-05\nEpoch 17/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 203ms/step - accuracy: 0.4416 - loss: 1.9233 - val_accuracy: 0.7203 - val_loss: 1.1227 - learning_rate: 1.0000e-05\nEpoch 18/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.4456 - loss: 1.8806 - val_accuracy: 0.7299 - val_loss: 1.0901 - learning_rate: 1.0000e-05\nEpoch 19/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.4551 - loss: 1.8614 - val_accuracy: 0.7363 - val_loss: 1.0565 - learning_rate: 1.0000e-05\nEpoch 20/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5064 - loss: 1.6783 - val_accuracy: 0.7556 - val_loss: 1.0235 - learning_rate: 1.0000e-05\nEpoch 21/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.4977 - loss: 1.7404 - val_accuracy: 0.7621 - val_loss: 0.9968 - learning_rate: 1.0000e-05\nEpoch 22/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.5087 - loss: 1.6743 - val_accuracy: 0.7781 - val_loss: 0.9754 - learning_rate: 1.0000e-05\nEpoch 23/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5176 - loss: 1.6571 - val_accuracy: 0.7814 - val_loss: 0.9623 - learning_rate: 1.0000e-05\nEpoch 24/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5555 - loss: 1.5304 - val_accuracy: 0.7814 - val_loss: 0.9418 - learning_rate: 1.0000e-05\nEpoch 25/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.5096 - loss: 1.5476 - val_accuracy: 0.7878 - val_loss: 0.9194 - learning_rate: 1.0000e-05\nEpoch 26/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.5151 - loss: 1.5714 - val_accuracy: 0.8006 - val_loss: 0.9049 - learning_rate: 1.0000e-05\nEpoch 27/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5597 - loss: 1.5043 - val_accuracy: 0.8006 - val_loss: 0.8916 - learning_rate: 1.0000e-05\nEpoch 28/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5522 - loss: 1.5325 - val_accuracy: 0.8135 - val_loss: 0.8699 - learning_rate: 1.0000e-05\nEpoch 29/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.5593 - loss: 1.4805 - val_accuracy: 0.8103 - val_loss: 0.8730 - learning_rate: 1.0000e-05\nEpoch 30/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.5541 - loss: 1.5384 - val_accuracy: 0.8199 - val_loss: 0.8559 - learning_rate: 1.0000e-05\nEpoch 31/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.5508 - loss: 1.4761 - val_accuracy: 0.8232 - val_loss: 0.8228 - learning_rate: 1.0000e-05\nEpoch 32/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5716 - loss: 1.4471 - val_accuracy: 0.8135 - val_loss: 0.8087 - learning_rate: 1.0000e-05\nEpoch 33/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6089 - loss: 1.3100 - val_accuracy: 0.8199 - val_loss: 0.8054 - learning_rate: 1.0000e-05\nEpoch 34/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.5913 - loss: 1.4067 - val_accuracy: 0.8264 - val_loss: 0.7933 - learning_rate: 1.0000e-05\nEpoch 35/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6251 - loss: 1.2977 - val_accuracy: 0.8232 - val_loss: 0.7810 - learning_rate: 1.0000e-05\nEpoch 36/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.6370 - loss: 1.1869 - val_accuracy: 0.8232 - val_loss: 0.7764 - learning_rate: 1.0000e-05\nEpoch 37/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6481 - loss: 1.2054 - val_accuracy: 0.8296 - val_loss: 0.7612 - learning_rate: 1.0000e-05\nEpoch 38/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6359 - loss: 1.2524 - val_accuracy: 0.8264 - val_loss: 0.7443 - learning_rate: 1.0000e-05\nEpoch 39/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6241 - loss: 1.2204 - val_accuracy: 0.8328 - val_loss: 0.7360 - learning_rate: 1.0000e-05\nEpoch 40/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6234 - loss: 1.2821 - val_accuracy: 0.8264 - val_loss: 0.7348 - learning_rate: 1.0000e-05\nEpoch 41/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6438 - loss: 1.1595 - val_accuracy: 0.8392 - val_loss: 0.7058 - learning_rate: 1.0000e-05\nEpoch 42/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6318 - loss: 1.1561 - val_accuracy: 0.8424 - val_loss: 0.6970 - learning_rate: 1.0000e-05\nEpoch 43/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6560 - loss: 1.1781 - val_accuracy: 0.8553 - val_loss: 0.6935 - learning_rate: 1.0000e-05\nEpoch 44/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6356 - loss: 1.1759 - val_accuracy: 0.8424 - val_loss: 0.6939 - learning_rate: 1.0000e-05\nEpoch 45/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6775 - loss: 1.1347 - val_accuracy: 0.8360 - val_loss: 0.6857 - learning_rate: 1.0000e-05\nEpoch 46/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.6599 - loss: 1.1126 - val_accuracy: 0.8457 - val_loss: 0.6805 - learning_rate: 1.0000e-05\nEpoch 47/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.6726 - loss: 1.0929 - val_accuracy: 0.8521 - val_loss: 0.6634 - learning_rate: 1.0000e-05\nEpoch 48/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7158 - loss: 0.9632 - val_accuracy: 0.8553 - val_loss: 0.6601 - learning_rate: 1.0000e-05\nEpoch 49/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6968 - loss: 1.0038 - val_accuracy: 0.8585 - val_loss: 0.6525 - learning_rate: 1.0000e-05\nEpoch 50/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.6963 - loss: 1.0680 - val_accuracy: 0.8521 - val_loss: 0.6399 - learning_rate: 1.0000e-05\nEpoch 51/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.6794 - loss: 1.0552 - val_accuracy: 0.8489 - val_loss: 0.6435 - learning_rate: 1.0000e-05\nEpoch 52/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7081 - loss: 1.0059 - val_accuracy: 0.8521 - val_loss: 0.6311 - learning_rate: 1.0000e-05\nEpoch 53/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7114 - loss: 0.9922 - val_accuracy: 0.8585 - val_loss: 0.6255 - learning_rate: 1.0000e-05\nEpoch 54/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 227ms/step - accuracy: 0.6990 - loss: 0.9883 - val_accuracy: 0.8617 - val_loss: 0.6163 - learning_rate: 1.0000e-05\nEpoch 55/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7292 - loss: 0.9237 - val_accuracy: 0.8617 - val_loss: 0.6125 - learning_rate: 1.0000e-05\nEpoch 56/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7450 - loss: 0.9100 - val_accuracy: 0.8617 - val_loss: 0.6028 - learning_rate: 1.0000e-05\nEpoch 57/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.7347 - loss: 0.9677 - val_accuracy: 0.8714 - val_loss: 0.5914 - learning_rate: 1.0000e-05\nEpoch 58/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7417 - loss: 0.8801 - val_accuracy: 0.8714 - val_loss: 0.5809 - learning_rate: 1.0000e-05\nEpoch 59/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7685 - loss: 0.8520 - val_accuracy: 0.8714 - val_loss: 0.5819 - learning_rate: 1.0000e-05\nEpoch 60/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7518 - loss: 0.8721 - val_accuracy: 0.8682 - val_loss: 0.5742 - learning_rate: 1.0000e-05\nEpoch 61/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7370 - loss: 0.8580 - val_accuracy: 0.8682 - val_loss: 0.5749 - learning_rate: 1.0000e-05\nEpoch 62/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.7688 - loss: 0.7929 - val_accuracy: 0.8714 - val_loss: 0.5669 - learning_rate: 1.0000e-05\nEpoch 63/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7477 - loss: 0.8444 - val_accuracy: 0.8682 - val_loss: 0.5586 - learning_rate: 1.0000e-05\nEpoch 64/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7671 - loss: 0.8146 - val_accuracy: 0.8714 - val_loss: 0.5516 - learning_rate: 1.0000e-05\nEpoch 65/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 204ms/step - accuracy: 0.7654 - loss: 0.8525 - val_accuracy: 0.8714 - val_loss: 0.5549 - learning_rate: 1.0000e-05\nEpoch 66/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7862 - loss: 0.7934 - val_accuracy: 0.8682 - val_loss: 0.5608 - learning_rate: 1.0000e-05\nEpoch 67/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.7636 - loss: 0.7863 - val_accuracy: 0.8778 - val_loss: 0.5655 - learning_rate: 1.0000e-05\nEpoch 68/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7767 - loss: 0.7650 - val_accuracy: 0.8778 - val_loss: 0.5667 - learning_rate: 2.0000e-06\nEpoch 69/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7759 - loss: 0.7965 - val_accuracy: 0.8746 - val_loss: 0.5524 - learning_rate: 2.0000e-06\nEpoch 70/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7598 - loss: 0.8354 - val_accuracy: 0.8778 - val_loss: 0.5521 - learning_rate: 2.0000e-06\nEpoch 71/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7845 - loss: 0.8137 - val_accuracy: 0.8778 - val_loss: 0.5557 - learning_rate: 1.0000e-06\nEpoch 72/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7685 - loss: 0.7879 - val_accuracy: 0.8778 - val_loss: 0.5599 - learning_rate: 1.0000e-06\nEpoch 73/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7816 - loss: 0.7616 - val_accuracy: 0.8778 - val_loss: 0.5625 - learning_rate: 1.0000e-06\nEpoch 74/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7789 - loss: 0.7918 - val_accuracy: 0.8746 - val_loss: 0.5531 - learning_rate: 1.0000e-06\nEpoch 75/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7762 - loss: 0.7992 - val_accuracy: 0.8746 - val_loss: 0.5499 - learning_rate: 1.0000e-06\nEpoch 76/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7563 - loss: 0.8753 - val_accuracy: 0.8746 - val_loss: 0.5545 - learning_rate: 1.0000e-06\nEpoch 77/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7850 - loss: 0.7515 - val_accuracy: 0.8746 - val_loss: 0.5564 - learning_rate: 1.0000e-06\nEpoch 78/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7799 - loss: 0.7655 - val_accuracy: 0.8746 - val_loss: 0.5567 - learning_rate: 1.0000e-06\nEpoch 79/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7839 - loss: 0.7158 - val_accuracy: 0.8714 - val_loss: 0.5499 - learning_rate: 1.0000e-06\nEpoch 80/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.7737 - loss: 0.7826 - val_accuracy: 0.8810 - val_loss: 0.5531 - learning_rate: 1.0000e-06\nEpoch 81/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 243ms/step - accuracy: 0.7768 - loss: 0.7894 - val_accuracy: 0.8842 - val_loss: 0.5470 - learning_rate: 1.0000e-06\nEpoch 82/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7878 - loss: 0.7436 - val_accuracy: 0.8778 - val_loss: 0.5511 - learning_rate: 1.0000e-06\nEpoch 83/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7593 - loss: 0.8052 - val_accuracy: 0.8810 - val_loss: 0.5421 - learning_rate: 1.0000e-06\nEpoch 84/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7734 - loss: 0.7832 - val_accuracy: 0.8778 - val_loss: 0.5406 - learning_rate: 1.0000e-06\nEpoch 85/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7936 - loss: 0.7121 - val_accuracy: 0.8810 - val_loss: 0.5337 - learning_rate: 1.0000e-06\nEpoch 86/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7663 - loss: 0.8049 - val_accuracy: 0.8810 - val_loss: 0.5395 - learning_rate: 1.0000e-06\nEpoch 87/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7925 - loss: 0.7242 - val_accuracy: 0.8810 - val_loss: 0.5447 - learning_rate: 1.0000e-06\nEpoch 88/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7533 - loss: 0.7989 - val_accuracy: 0.8842 - val_loss: 0.5387 - learning_rate: 1.0000e-06\nEpoch 89/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7623 - loss: 0.8263 - val_accuracy: 0.8810 - val_loss: 0.5353 - learning_rate: 1.0000e-06\nEpoch 90/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7858 - loss: 0.8051 - val_accuracy: 0.8778 - val_loss: 0.5347 - learning_rate: 1.0000e-06\nEpoch 91/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7863 - loss: 0.7440 - val_accuracy: 0.8778 - val_loss: 0.5267 - learning_rate: 1.0000e-06\nEpoch 92/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7863 - loss: 0.7833 - val_accuracy: 0.8778 - val_loss: 0.5333 - learning_rate: 1.0000e-06\nEpoch 93/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7930 - loss: 0.7322 - val_accuracy: 0.8810 - val_loss: 0.5316 - learning_rate: 1.0000e-06\nEpoch 94/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7497 - loss: 0.8450 - val_accuracy: 0.8810 - val_loss: 0.5334 - learning_rate: 1.0000e-06\nEpoch 95/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7587 - loss: 0.8488 - val_accuracy: 0.8810 - val_loss: 0.5372 - learning_rate: 1.0000e-06\nEpoch 96/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7718 - loss: 0.7573 - val_accuracy: 0.8842 - val_loss: 0.5419 - learning_rate: 1.0000e-06\nEpoch 97/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7665 - loss: 0.7653 - val_accuracy: 0.8842 - val_loss: 0.5456 - learning_rate: 1.0000e-06\nEpoch 98/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7598 - loss: 0.8207 - val_accuracy: 0.8810 - val_loss: 0.5477 - learning_rate: 1.0000e-06\nEpoch 99/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7880 - loss: 0.7623 - val_accuracy: 0.8810 - val_loss: 0.5480 - learning_rate: 1.0000e-06\nEpoch 100/100\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7555 - loss: 0.8225 - val_accuracy: 0.8810 - val_loss: 0.5484 - learning_rate: 1.0000e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"history = custom_model.fit(\n    training_data_flow,\n    validation_data=validation_data_flow,\n    epochs=15,  # Number of epochs to train for\n    callbacks=[\n        #early_stopping_callback,  # Stop training if validation loss doesn't improve\n        checkpoint_callback,  # Save the best model\n        learning_rate_reduction_callback  # Reduce learning rate if validation loss doesn't improve\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:07:03.300102Z","iopub.execute_input":"2024-09-07T11:07:03.300848Z","iopub.status.idle":"2024-09-07T11:09:09.626905Z","shell.execute_reply.started":"2024-09-07T11:07:03.300808Z","shell.execute_reply":"2024-09-07T11:09:09.625958Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 205ms/step - accuracy: 0.7595 - loss: 0.8135 - val_accuracy: 0.8842 - val_loss: 0.5480 - learning_rate: 1.0000e-06\nEpoch 2/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7784 - loss: 0.7413 - val_accuracy: 0.8842 - val_loss: 0.5433 - learning_rate: 1.0000e-06\nEpoch 3/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7789 - loss: 0.7867 - val_accuracy: 0.8842 - val_loss: 0.5314 - learning_rate: 1.0000e-06\nEpoch 4/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 201ms/step - accuracy: 0.7877 - loss: 0.7184 - val_accuracy: 0.8842 - val_loss: 0.5339 - learning_rate: 1.0000e-06\nEpoch 5/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7599 - loss: 0.7935 - val_accuracy: 0.8842 - val_loss: 0.5278 - learning_rate: 1.0000e-06\nEpoch 6/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.8032 - loss: 0.7062 - val_accuracy: 0.8810 - val_loss: 0.5308 - learning_rate: 1.0000e-06\nEpoch 7/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7753 - loss: 0.7518 - val_accuracy: 0.8842 - val_loss: 0.5213 - learning_rate: 1.0000e-06\nEpoch 8/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 242ms/step - accuracy: 0.7628 - loss: 0.8246 - val_accuracy: 0.8875 - val_loss: 0.5261 - learning_rate: 1.0000e-06\nEpoch 9/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7645 - loss: 0.8585 - val_accuracy: 0.8842 - val_loss: 0.5305 - learning_rate: 1.0000e-06\nEpoch 10/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7693 - loss: 0.7655 - val_accuracy: 0.8875 - val_loss: 0.5333 - learning_rate: 1.0000e-06\nEpoch 11/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7955 - loss: 0.7113 - val_accuracy: 0.8842 - val_loss: 0.5368 - learning_rate: 1.0000e-06\nEpoch 12/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7752 - loss: 0.7988 - val_accuracy: 0.8875 - val_loss: 0.5397 - learning_rate: 1.0000e-06\nEpoch 13/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7871 - loss: 0.7878 - val_accuracy: 0.8875 - val_loss: 0.5413 - learning_rate: 1.0000e-06\nEpoch 14/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7752 - loss: 0.7632 - val_accuracy: 0.8875 - val_loss: 0.5178 - learning_rate: 1.0000e-06\nEpoch 15/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7798 - loss: 0.7394 - val_accuracy: 0.8875 - val_loss: 0.5153 - learning_rate: 1.0000e-06\n","output_type":"stream"}]},{"cell_type":"code","source":"history = custom_model.fit(\n    training_data_flow,\n    validation_data=validation_data_flow,\n    epochs=15,  # Number of epochs to train for\n    callbacks=[\n        #early_stopping_callback,  # Stop training if validation loss doesn't improve\n        checkpoint_callback,  # Save the best model\n        learning_rate_reduction_callback  # Reduce learning rate if validation loss doesn't improve\n    ]\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:09:52.743281Z","iopub.execute_input":"2024-09-07T11:09:52.744055Z","iopub.status.idle":"2024-09-07T11:11:58.219390Z","shell.execute_reply.started":"2024-09-07T11:09:52.744015Z","shell.execute_reply":"2024-09-07T11:11:58.218611Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Epoch 1/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 207ms/step - accuracy: 0.7896 - loss: 0.7580 - val_accuracy: 0.8842 - val_loss: 0.5192 - learning_rate: 1.0000e-06\nEpoch 2/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7691 - loss: 0.8204 - val_accuracy: 0.8842 - val_loss: 0.5196 - learning_rate: 1.0000e-06\nEpoch 3/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7769 - loss: 0.7227 - val_accuracy: 0.8875 - val_loss: 0.5148 - learning_rate: 1.0000e-06\nEpoch 4/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7877 - loss: 0.7784 - val_accuracy: 0.8875 - val_loss: 0.5170 - learning_rate: 1.0000e-06\nEpoch 5/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7755 - loss: 0.7367 - val_accuracy: 0.8875 - val_loss: 0.5124 - learning_rate: 1.0000e-06\nEpoch 6/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7986 - loss: 0.7600 - val_accuracy: 0.8875 - val_loss: 0.5163 - learning_rate: 1.0000e-06\nEpoch 7/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7888 - loss: 0.7282 - val_accuracy: 0.8875 - val_loss: 0.5224 - learning_rate: 1.0000e-06\nEpoch 8/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7811 - loss: 0.7739 - val_accuracy: 0.8875 - val_loss: 0.5244 - learning_rate: 1.0000e-06\nEpoch 9/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7734 - loss: 0.7803 - val_accuracy: 0.8875 - val_loss: 0.5187 - learning_rate: 1.0000e-06\nEpoch 10/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7728 - loss: 0.7831 - val_accuracy: 0.8875 - val_loss: 0.5233 - learning_rate: 1.0000e-06\nEpoch 11/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7685 - loss: 0.8089 - val_accuracy: 0.8842 - val_loss: 0.5189 - learning_rate: 1.0000e-06\nEpoch 12/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7578 - loss: 0.7918 - val_accuracy: 0.8875 - val_loss: 0.5209 - learning_rate: 1.0000e-06\nEpoch 13/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 203ms/step - accuracy: 0.7752 - loss: 0.7819 - val_accuracy: 0.8842 - val_loss: 0.5261 - learning_rate: 1.0000e-06\nEpoch 14/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.7672 - loss: 0.8419 - val_accuracy: 0.8842 - val_loss: 0.5142 - learning_rate: 1.0000e-06\nEpoch 15/15\n\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 202ms/step - accuracy: 0.8091 - loss: 0.7005 - val_accuracy: 0.8875 - val_loss: 0.5119 - learning_rate: 1.0000e-06\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Evaluating the Model","metadata":{}},{"cell_type":"code","source":"# Get the first batch of data and labels from the test generator\ntest_batch = next(iter(testing_data_flow))\n\n# Get the true labels\ntrue_labels = np.argmax(test_batch[1], axis=1)\n\n# Get the predicted labels\npredicted_probabilities = custom_model.predict(test_batch[0])\n\n# Get the predicted labels\npredicted_labels = np.argmax(predicted_probabilities, axis=1)\n\n# Print the classification report\nfrom sklearn.metrics import classification_report\nprint(classification_report(true_labels, predicted_labels))\n\n# Print the confusion matrix\nfrom sklearn.metrics import confusion_matrix\nprint(confusion_matrix(true_labels, predicted_labels))\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:15:13.891239Z","iopub.execute_input":"2024-09-07T11:15:13.891976Z","iopub.status.idle":"2024-09-07T11:15:28.302672Z","shell.execute_reply.started":"2024-09-07T11:15:13.891939Z","shell.execute_reply":"2024-09-07T11:15:28.301611Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 14s/step\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00         3\n           1       1.00      1.00      1.00         3\n           2       1.00      1.00      1.00         4\n           3       1.00      1.00      1.00         2\n           4       1.00      0.33      0.50         3\n           5       1.00      1.00      1.00         3\n           6       0.67      1.00      0.80         2\n           7       1.00      1.00      1.00         1\n           8       1.00      1.00      1.00         1\n           9       0.75      1.00      0.86         3\n          10       0.50      1.00      0.67         1\n          11       1.00      1.00      1.00         1\n          12       0.00      0.00      0.00         1\n          13       1.00      1.00      1.00         3\n          14       1.00      1.00      1.00         1\n\n    accuracy                           0.91        32\n   macro avg       0.86      0.89      0.85        32\nweighted avg       0.91      0.91      0.89        32\n\n[[3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 1 0 0 0 0 1 1 0 0 0 0]\n [0 0 0 0 0 3 0 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 3 0]\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]]\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"The model achieved an accuracy of 0.91, indicating a strong performance on the test dataset. The macro average precision, recall, and F1-score were 0.86, 0.89, and 0.85, respectively, suggesting a good balance between precision and recall. The model performed well on most classes, with precision and recall values close to 1.0. However, class 4 had a lower recall value of 0.33, indicating some room for improvement. The weighted average precision, recall, and F1-score were also high, indicating that the model performed well across all classes. \n\n*For the purpose of this project, the model's performance is deemed satisfactory, and further improvements can be considered in future iterations if any.*","metadata":{}},{"cell_type":"markdown","source":"Saving the model file","metadata":{}},{"cell_type":"code","source":"# Save the custom model\ncustom_model.save('kaggle/working/animal_classification_model.h5')\n","metadata":{"execution":{"iopub.status.busy":"2024-09-07T11:28:28.753628Z","iopub.execute_input":"2024-09-07T11:28:28.754389Z","iopub.status.idle":"2024-09-07T11:28:30.372188Z","shell.execute_reply.started":"2024-09-07T11:28:28.754336Z","shell.execute_reply":"2024-09-07T11:28:30.371150Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"The custom model is saved as a file named animal_classification_model.h5 in the kaggle/working directory.\n\nIn addition to saving the entire model, the best-performing model with weights as a checkpoint file during training was also saved. The main difference between these two files is: The animal_classification_model.h5 file contains the entire model architecture, including the weights and the model's configuration.The checkpoint file contains only the weights of the best-performing model, which can be used to restore the model's state and make predictions.\n\nThe animal_classification_model.h5 file can be used to: Load the entire model and make predictions, Fine-tune the model on new data, Modify the model's architecture and retrain it.\n\nThe checkpoint file can be used to: Restore the model's state and make predictions, Continue training the model from where it left off, Use the model's weights to initialize a new model","metadata":{}}]}